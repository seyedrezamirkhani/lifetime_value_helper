{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6affd365-1261-42e1-a3f4-8df0bece88e9",
   "metadata": {},
   "source": [
    "This notebooks creates two simple models to test the zero_inflated_lognormal_loss and zero_inflated_lognormal_pred functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b4e49e9-be18-4a50-9dfb-c4e5afc92ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 03:40:20.920062: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 03:40:20.934598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732678820.952442   22258 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732678820.957609   22258 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-27 03:40:20.975578: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1732678823.655037   22258 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21952 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:73:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732678825.440774   22545 service.cc:148] XLA service 0x7116200054f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732678825.440800   22545 service.cc:156]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2024-11-27 03:40:25.465688: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1732678825.569909   22545 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-11-27 03:40:25.598107: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:930] The NVIDIA driver's CUDA version is 12.4 which is older than the PTX compiler version 12.5.82. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 5/13\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5248"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732678826.144651   22545 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 2.0155\n",
      "Epoch 2/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 1.8987\n",
      "Epoch 3/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 1.7004\n",
      "Epoch 4/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 1.6420\n",
      "Epoch 5/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 1.1358\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "tf.Tensor(\n",
      "[[0.75887877]\n",
      " [0.49784434]\n",
      " [0.7908647 ]\n",
      " [0.52344847]\n",
      " [0.36860684]\n",
      " [0.6048921 ]\n",
      " [0.6135791 ]\n",
      " [0.48161823]\n",
      " [0.55851084]\n",
      " [0.69017845]\n",
      " [0.9484566 ]\n",
      " [0.81077814]\n",
      " [0.45143124]\n",
      " [0.83044475]\n",
      " [0.84114456]\n",
      " [0.5435112 ]\n",
      " [0.5966114 ]\n",
      " [0.6808903 ]\n",
      " [0.6157578 ]\n",
      " [0.63696855]\n",
      " [0.47810385]\n",
      " [0.6918385 ]\n",
      " [0.66810524]\n",
      " [0.4218409 ]\n",
      " [0.44046035]\n",
      " [0.72947735]\n",
      " [0.8873009 ]\n",
      " [0.5684222 ]\n",
      " [0.68851537]\n",
      " [0.4958669 ]\n",
      " [0.7651763 ]\n",
      " [0.71155834]\n",
      " [0.571057  ]\n",
      " [0.88508797]\n",
      " [0.72174656]\n",
      " [0.62838167]\n",
      " [0.85353214]\n",
      " [0.40071723]\n",
      " [0.76312727]\n",
      " [0.65435815]\n",
      " [0.6092251 ]\n",
      " [0.866784  ]\n",
      " [0.5050497 ]\n",
      " [0.65275615]\n",
      " [0.566947  ]\n",
      " [0.66522086]\n",
      " [0.45004877]\n",
      " [0.53204846]\n",
      " [0.52348864]\n",
      " [0.5480601 ]\n",
      " [0.5539597 ]\n",
      " [0.62592894]\n",
      " [0.52915466]\n",
      " [0.7875629 ]\n",
      " [0.4378509 ]\n",
      " [0.42288232]\n",
      " [0.6923916 ]\n",
      " [0.42902842]\n",
      " [0.4134309 ]\n",
      " [0.6417203 ]\n",
      " [0.44286385]\n",
      " [0.38760042]\n",
      " [0.5971288 ]\n",
      " [0.8033644 ]\n",
      " [0.49440062]\n",
      " [0.7538443 ]\n",
      " [0.7135756 ]\n",
      " [0.58721995]\n",
      " [0.60457456]\n",
      " [0.6427601 ]\n",
      " [0.8045252 ]\n",
      " [0.70522225]\n",
      " [0.60342747]\n",
      " [0.6132649 ]\n",
      " [0.5088517 ]\n",
      " [0.44379866]\n",
      " [0.78040034]\n",
      " [0.5821828 ]\n",
      " [0.4209277 ]\n",
      " [0.48867324]\n",
      " [0.71453345]\n",
      " [0.70635104]\n",
      " [0.5028229 ]\n",
      " [0.6059372 ]\n",
      " [0.5447431 ]\n",
      " [0.5501441 ]\n",
      " [0.82679874]\n",
      " [0.44334805]\n",
      " [0.42294613]\n",
      " [0.4148138 ]\n",
      " [0.42307076]\n",
      " [0.62194985]\n",
      " [0.40186664]\n",
      " [0.9089915 ]\n",
      " [0.74239314]\n",
      " [0.7717983 ]\n",
      " [0.93292695]\n",
      " [0.6256971 ]\n",
      " [0.58248764]\n",
      " [0.5386348 ]], shape=(100, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "#!pip install -q git+https://github.com/seyedrezamirkhani/lifetime_value\n",
    "from lifetime_value import zero_inflated_lognormal_loss, zero_inflated_lognormal_pred\n",
    "\n",
    "# Define a simple model\n",
    "model = Sequential([\n",
    "    Input(shape=(10,)),  # Example input shape with 10 features\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(3)  # Output layer with 3 logits as required by the loss function\n",
    "])\n",
    "\n",
    "# Compile the model with the custom loss\n",
    "model.compile(optimizer='adam', loss=zero_inflated_lognormal_loss)\n",
    "\n",
    "# Example data\n",
    "import numpy as np\n",
    "X_train = np.random.rand(100, 10)  # 100 samples, 10 features\n",
    "y_train = np.random.rand(100, 1)  # 100 samples, single target value\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=8)\n",
    "\n",
    "# Predicting values\n",
    "predictions = zero_inflated_lognormal_pred(model.predict(X_train))\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ea95d-fec1-4c09-b258-e2d4898daf5c",
   "metadata": {},
   "source": [
    "# Model with additional categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a622ecc1-244a-45d6-9b42-4745eae808d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reza/miniconda3/envs/clv-google/lib/python3.12/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['numerical_input', 'category1_input', 'category2_input']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 1.6831\n",
      "Epoch 2/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 1.3244\n",
      "Epoch 3/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 1.2115\n",
      "Epoch 4/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.9898\n",
      "Epoch 5/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 1.0536\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "tf.Tensor(\n",
      "[[0.74605304]\n",
      " [0.52685773]\n",
      " [0.39616117]\n",
      " [0.5991483 ]\n",
      " [0.5314727 ]\n",
      " [0.5276166 ]\n",
      " [0.51430744]\n",
      " [0.43916154]\n",
      " [0.5821831 ]\n",
      " [0.53900295]\n",
      " [0.4663026 ]\n",
      " [0.6688629 ]\n",
      " [0.5265674 ]\n",
      " [0.56457204]\n",
      " [0.54849803]\n",
      " [0.3828179 ]\n",
      " [0.4745946 ]\n",
      " [0.6066542 ]\n",
      " [0.45148453]\n",
      " [0.5177393 ]\n",
      " [0.60551846]\n",
      " [0.76076317]\n",
      " [0.49445522]\n",
      " [0.50284374]\n",
      " [0.50868654]\n",
      " [0.573168  ]\n",
      " [0.48313934]\n",
      " [0.8014265 ]\n",
      " [0.5039399 ]\n",
      " [0.5201338 ]\n",
      " [0.63865423]\n",
      " [0.45293432]\n",
      " [0.5919541 ]\n",
      " [0.54147404]\n",
      " [0.5287366 ]\n",
      " [0.57257414]\n",
      " [0.63298863]\n",
      " [0.74288654]\n",
      " [0.5587259 ]\n",
      " [0.5123839 ]\n",
      " [0.5060755 ]\n",
      " [0.5487583 ]\n",
      " [0.54687804]\n",
      " [0.47431076]\n",
      " [0.53590333]\n",
      " [0.42739376]\n",
      " [0.57900393]\n",
      " [0.763692  ]\n",
      " [0.5533977 ]\n",
      " [0.47933736]\n",
      " [0.40624294]\n",
      " [0.47309086]\n",
      " [0.56787604]\n",
      " [0.4544618 ]\n",
      " [0.5057582 ]\n",
      " [0.44556302]\n",
      " [0.5505251 ]\n",
      " [0.6213543 ]\n",
      " [0.5135148 ]\n",
      " [0.47555992]\n",
      " [0.5918289 ]\n",
      " [0.5243407 ]\n",
      " [0.5982097 ]\n",
      " [0.59348977]\n",
      " [0.49919477]\n",
      " [0.5542509 ]\n",
      " [0.5082041 ]\n",
      " [0.61242115]\n",
      " [0.5121861 ]\n",
      " [0.5063998 ]\n",
      " [0.4860315 ]\n",
      " [0.53307676]\n",
      " [0.60867774]\n",
      " [0.59456474]\n",
      " [0.44901156]\n",
      " [0.5456648 ]\n",
      " [0.5972953 ]\n",
      " [0.45740005]\n",
      " [0.4987327 ]\n",
      " [0.5402661 ]\n",
      " [0.55038893]\n",
      " [0.5281702 ]\n",
      " [0.5229103 ]\n",
      " [0.3924531 ]\n",
      " [0.54256284]\n",
      " [0.5110159 ]\n",
      " [0.5506019 ]\n",
      " [0.47310156]\n",
      " [0.5983643 ]\n",
      " [0.50743043]\n",
      " [0.5151383 ]\n",
      " [0.53216666]\n",
      " [0.5857394 ]\n",
      " [0.4844263 ]\n",
      " [0.44216272]\n",
      " [0.5958339 ]\n",
      " [0.5853392 ]\n",
      " [0.39629552]\n",
      " [0.6593681 ]\n",
      " [0.6040936 ]], shape=(100, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, Flatten, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#!pip install -q git+https://github.com/seyedrezamirkhani/lifetime_value\n",
    "from lifetime_value import zero_inflated_lognormal_loss, zero_inflated_lognormal_pred\n",
    "\n",
    "# Define numerical input\n",
    "numerical_input = Input(shape=(10,), name='numerical_input')  # Example with 10 numerical features\n",
    "\n",
    "# Define categorical inputs\n",
    "category1_input = Input(shape=(1,), name='category1_input')  # First categorical feature\n",
    "category2_input = Input(shape=(1,), name='category2_input')  # Second categorical feature\n",
    "\n",
    "# Embedding layers for categorical features\n",
    "embedding_dim = 4  # Example embedding size, can be adjusted\n",
    "category1_embedding = Embedding(input_dim=50, output_dim=embedding_dim, name='category1_embedding')(category1_input)\n",
    "category2_embedding = Embedding(input_dim=50, output_dim=embedding_dim, name='category2_embedding')(category2_input)\n",
    "\n",
    "# Flatten embeddings\n",
    "category1_flatten = Flatten()(category1_embedding)\n",
    "category2_flatten = Flatten()(category2_embedding)\n",
    "\n",
    "# Concatenate all inputs\n",
    "concat_inputs = Concatenate()([numerical_input, category1_flatten, category2_flatten])\n",
    "\n",
    "# Dense layers for processing\n",
    "x = Dense(16, activation='relu')(concat_inputs)\n",
    "output = Dense(3)(x)  # Output layer with 3 logits for the custom loss\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[numerical_input, category1_input, category2_input], outputs=output)\n",
    "\n",
    "# Compile the model with the custom loss\n",
    "model.compile(optimizer=Adam(), loss=zero_inflated_lognormal_loss)\n",
    "\n",
    "# Example data\n",
    "import numpy as np\n",
    "X_numerical = np.random.rand(100, 10)  # 100 samples, 10 numerical features\n",
    "X_category1 = np.random.randint(0, 50, size=(100, 1))  # 100 samples, single categorical feature\n",
    "X_category2 = np.random.randint(0, 50, size=(100, 1))  # 100 samples, second categorical feature\n",
    "y_train = np.random.rand(100, 1)  # 100 samples, single target value\n",
    "\n",
    "# Fit the model\n",
    "model.fit([X_numerical, X_category1, X_category2], y_train, epochs=5, batch_size=8)\n",
    "\n",
    "# Predicting values\n",
    "predictions = zero_inflated_lognormal_pred(model.predict([X_numerical, X_category1, X_category2]))\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360fba5-beb8-4e98-b301-be05bd103479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
